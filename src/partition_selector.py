'''
==================================================
File: partition_selector.py
Project: ReNOS
File Created: Tuesday, 21st October 2025
Author: Jakub Jastrzebski (jakubandrzej.jastrzebski@polimi.it)
Under the supervision of: Politecnico di Milano
==================================================
'''

"""
Tool to select optimal partitioning strategies based on FLOPs balance.
Reads CSV files generated by partitioner_detailed.py and selects configurations
that achieve target FLOPs per partition with minimal variance.
"""

import pandas as pd
import numpy as np
import os
from pathlib import Path
from typing import Dict, List, Tuple
import json


class PartitionSelector:
    """Selects partitioning strategies based on balanced FLOPs per partition."""

    def __init__(self, data_path: str):
        """
        Initialize selector with path to CSV data directory.

        Args:
            data_path: Path to directory containing layer_*.csv files
        """
        self.data_path = Path(data_path)
        self.layer_data: Dict[int, pd.DataFrame] = {}
        self.load_layer_data()

    def load_layer_data(self):
        """Load all layer CSV files from the data directory."""
        csv_files = sorted(self.data_path.glob("layer_*.csv"))

        for csv_file in csv_files:
            # Extract layer index from filename: layer_1_conv2d_fused.csv -> 1
            filename = csv_file.stem  # Remove .csv
            parts = filename.split('_')

            # Skip files that don't follow layer_N_* pattern
            if len(parts) < 2 or not parts[1].isdigit():
                continue

            layer_idx = int(parts[1])

            df = pd.read_csv(csv_file)
            # Filter out error rows
            df = df[df['num_partitions'] != 'ERROR'].copy()
            df['num_partitions'] = df['num_partitions'].astype(int)

            self.layer_data[layer_idx] = df
            print(f"Loaded layer {layer_idx}: {len(df)} valid partitioning strategies")

    def select_by_flops_per_partition(
        self,
        target_flops_per_partition: float,
        tolerance: float = 0.2,
        max_candidates: int = 5
    ) -> Dict[int, List[Tuple[int, int, int]]]:
        """
        Select partitioning strategies that achieve target FLOPs per partition.

        Selects strategies where mean_flops is close to target and minimizes
        std_flops (balanced computation across partitions).

        Args:
            target_flops_per_partition: Target FLOPs per partition (e.g., 1e6)
            tolerance: Acceptable deviation from target (e.g., 0.2 = ±20%)
            max_candidates: Maximum candidates to return per layer

        Returns:
            Dict mapping layer_idx -> list of (spatial, out_ch, in_ch) tuples
        """
        results = {}

        for layer_idx, df in self.layer_data.items():
            layer_name = df['layer_name'].iloc[0]
            layer_type = df['layer_type'].iloc[0]

            print(f"\n{'='*80}")
            print(f"Layer {layer_idx}: {layer_name} ({layer_type})")
            print(f"{'='*80}")

            # Calculate target range
            min_flops = target_flops_per_partition * (1 - tolerance)
            max_flops = target_flops_per_partition * (1 + tolerance)

            # Filter by target FLOPs per partition
            df_filtered = df[
                (df['mean_flops'] >= min_flops) &
                (df['mean_flops'] <= max_flops)
            ].copy()

            if len(df_filtered) == 0:
                print(f"  WARNING: No strategies found in range [{min_flops:.2e}, {max_flops:.2e}]")
                print(f"  Available range: [{df['mean_flops'].min():.2e}, {df['mean_flops'].max():.2e}]")
                # Select closest option
                df['flops_distance'] = abs(df['mean_flops'] - target_flops_per_partition)
                closest = df.nsmallest(1, 'flops_distance').iloc[0]
                print(f"  Using closest: ({closest['spatial']}, {closest['out_ch']}, {closest['in_ch']}) "
                      f"with {closest['mean_flops']:.2e} FLOPs/partition, "
                      f"size_per_partition={closest['mean_partition_size']:,.0f} bytes")
                results[layer_idx] = [(int(closest['spatial']), int(closest['out_ch']), int(closest['in_ch']))]
                continue

            # Calculate balance metric: coefficient of variation (std/mean)
            # Lower CV = more balanced partitions
            df_filtered['flops_cv'] = df_filtered['std_flops'] / df_filtered['mean_flops']
            df_filtered['flops_cv'] = df_filtered['flops_cv'].fillna(0)  # Handle single partition case

            # Sort by: 1) lowest CV (most balanced), 2) closest to target, 3) smallest size
            df_filtered['flops_distance'] = abs(df_filtered['mean_flops'] - target_flops_per_partition)
            df_sorted = df_filtered.sort_values(['flops_cv', 'flops_distance', 'mean_partition_size'])

            # Select top candidates
            candidates = df_sorted.head(max_candidates)

            print(f"  Found {len(df_filtered)} strategies in target range")
            print(f"  Top {len(candidates)} candidates:")

            selected = []
            for idx, row in candidates.iterrows():
                config = (int(row['spatial']), int(row['out_ch']), int(row['in_ch']))
                selected.append(config)

                print(f"    {config}: "
                      f"mean_flops={row['mean_flops']:.2e}, "
                      f"CV={row['flops_cv']:.4f}, "
                      f"size_per_partition={row['mean_partition_size']:,.0f} bytes, "
                      f"num_partitions={row['num_partitions']}, "
                      f"total_size={row['total_size']:,.0f} bytes")

            results[layer_idx] = selected

        return results

    def select_by_size_per_partition(
        self,
        target_size_per_partition: float,
        tolerance: float = 0.2,
        max_candidates: int = 5
    ) -> Dict[int, List[Tuple[int, int, int]]]:
        """
        Select partitioning strategies that achieve target size per partition.

        Selects strategies where mean_partition_size is close to target and minimizes
        std_partition_size (balanced memory across partitions).

        Args:
            target_size_per_partition: Target size per partition in bytes (e.g., 50000)
            tolerance: Acceptable deviation from target (e.g., 0.2 = ±20%)
            max_candidates: Maximum candidates to return per layer

        Returns:
            Dict mapping layer_idx -> list of (spatial, out_ch, in_ch) tuples
        """
        results = {}

        for layer_idx, df in self.layer_data.items():
            layer_name = df['layer_name'].iloc[0]
            layer_type = df['layer_type'].iloc[0]

            print(f"\n{'='*80}")
            print(f"Layer {layer_idx}: {layer_name} ({layer_type})")
            print(f"{'='*80}")

            # Calculate target range
            min_size = target_size_per_partition * (1 - tolerance)
            max_size = target_size_per_partition * (1 + tolerance)

            # Filter by target size per partition
            df_filtered = df[
                (df['mean_partition_size'] >= min_size) &
                (df['mean_partition_size'] <= max_size)
            ].copy()

            if len(df_filtered) == 0:
                print(f"  WARNING: No strategies found in range [{min_size:,.0f}, {max_size:,.0f}] bytes")
                print(f"  Available range: [{df['mean_partition_size'].min():,.0f}, {df['mean_partition_size'].max():,.0f}] bytes")
                # Select closest option
                df['size_distance'] = abs(df['mean_partition_size'] - target_size_per_partition)
                closest = df.nsmallest(1, 'size_distance').iloc[0]
                print(f"  Using closest: ({closest['spatial']}, {closest['out_ch']}, {closest['in_ch']}) "
                    f"with size_per_partition={closest['mean_partition_size']:,.0f} bytes, "
                    f"mean_flops={closest['mean_flops']:.2e}")
                results[layer_idx] = [(int(closest['spatial']), int(closest['out_ch']), int(closest['in_ch']))]
                continue

            # Calculate balance metric: coefficient of variation (std/mean)
            # Lower CV = more balanced partitions
            df_filtered['size_cv'] = df_filtered['std_partition_size'] / df_filtered['mean_partition_size']
            df_filtered['size_cv'] = df_filtered['size_cv'].fillna(0)  # Handle single partition case

            # Sort by: 1) lowest CV (most balanced), 2) closest to target, 3) smallest FLOPs (fastest)
            df_filtered['size_distance'] = abs(df_filtered['mean_partition_size'] - target_size_per_partition)
            df_sorted = df_filtered.sort_values(['size_cv', 'size_distance', 'mean_flops'])

            # Select top candidates
            candidates = df_sorted.head(max_candidates)

            print(f"  Found {len(df_filtered)} strategies in target range")
            print(f"  Top {len(candidates)} candidates:")

            selected = []
            for idx, row in candidates.iterrows():
                config = (int(row['spatial']), int(row['out_ch']), int(row['in_ch']))
                selected.append(config)

                print(f"    {config}: "
                    f"size_per_partition={row['mean_partition_size']} bytes, "
                    f"CV={row['size_cv']:.2f}, "
                    f"mean_flops={row['mean_flops']:.2e}, "
                    f"num_partitions={row['num_partitions']}, "
                    f"total_size={row['total_size']:,.0f} bytes")

            results[layer_idx] = selected

        return results

    def export_configuration(
        self,
        selected_strategies: Dict[int, List[Tuple[int, int, int]]],
        output_file: str,
        strategy_index: int = 0
    ) -> Dict[int, Tuple[int, int, int]]:
        """
        Export a single configuration (one strategy per layer) to a file.

        Args:
            selected_strategies: Dict from select_by_flops_per_partition
            output_file: Path to output JSON file
            strategy_index: Which candidate to use (0 = best)

        Returns:
            Dict mapping layer_idx -> (spatial, out_ch, in_ch) tuple
        """
        config = {}
        for layer_idx, candidates in selected_strategies.items():
            if strategy_index < len(candidates):
                config[str(layer_idx)] = candidates[strategy_index]
            else:
                config[str(layer_idx)] = candidates[0]  # Fallback to best

        with open(output_file, 'w') as f:
            json.dump(config, f, indent=2)

        print(f"\n{'='*80}")
        print(f"Configuration exported to: {output_file}")
        print(f"{'='*80}")
        for layer_idx, strategy in config.items():
            print(f"  Layer {layer_idx}: {strategy}")

        return {int(k): v for k, v in config.items()}


if __name__ == '__main__':
    import sys

    # Example usage
    data_path = "./data/partitioner_data15Oct"
    selector = PartitionSelector(data_path)

    # Parse command line arguments
    if len(sys.argv) < 3:
        print("Usage: python partition_selector.py [flops|size] <target_value>")
        print("Examples:")
        print("  python partition_selector.py flops 500000      # 500K FLOPs per partition")
        print("  python partition_selector.py size 100000       # 100KB per partition")
        sys.exit(1)

    mode = sys.argv[1].lower()
    target = float(sys.argv[2])

    if mode == 'flops':
        print("\n" + "="*80)
        print("PARTITION STRATEGY SELECTION BY FLOPS PER PARTITION")
        print("="*80)

        # Select by target FLOPs per partition
        strategies = selector.select_by_flops_per_partition(
            target_flops_per_partition=target,
            tolerance=0.3,  # ±30%
            max_candidates=10
        )

        # Export best configuration
        config = selector.export_configuration(
            strategies,
            output_file=f"{data_path}/config_flops_{int(target)}.json",
            strategy_index=0
        )

    elif mode == 'size':
        print("\n" + "="*80)
        print("PARTITION STRATEGY SELECTION BY SIZE PER PARTITION")
        print("="*80)

        # Select by target size per partition
        strategies = selector.select_by_size_per_partition(
            target_size_per_partition=target,
            tolerance=0.3,  # ±30%
            max_candidates=10
        )

        # Export best configuration
        config = selector.export_configuration(
            strategies,
            output_file=f"{data_path}/config_size_{int(target)}.json",
            strategy_index=0
        )

    else:
        print(f"ERROR: Unknown mode '{mode}'. Use 'flops' or 'size'")
        sys.exit(1)
